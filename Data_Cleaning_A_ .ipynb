{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "-iKsSHUP-P8E",
    "outputId": "25730246-4261-4627-d250-518413843051"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Avin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Avin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Avin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout, Bidirectional, Dropout\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "VTeRUm4xB3V2",
    "outputId": "a96f05b2-6e23-4b73-a1c2-ab38e6ae197c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File databackup.csv does not exist: 'databackup.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe7672cb1c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load the data csv from google drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhouse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'databackup.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhouse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File databackup.csv does not exist: 'databackup.csv'"
     ]
    }
   ],
   "source": [
    "#Load the data csv from google drive\n",
    "house_data = pd.read_csv('/content/drive/My Drive/databackup.csv')\n",
    "house_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "QXd4QD8YLRhn",
    "outputId": "82bab818-9a8a-41c9-ecef-5bc0c65ddcad"
   },
   "outputs": [],
   "source": [
    "#Print the datatypes \n",
    "house_data.info()\n",
    "\n",
    "#All variables are string and there are 11 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0yp9Y1YLX5g"
   },
   "outputs": [],
   "source": [
    "#Drop the rows with nulls\n",
    "house_data = house_data.dropna() \n",
    "house_data = house_data.iloc[1:] #removing the 1st row of the dataframe as it does not have any data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk5IuyM2CWLz"
   },
   "source": [
    "Tidying up\n",
    "\n",
    "\n",
    "The response variable is house price.\n",
    "The predictors can be multiple, including the suburb, amenities, description, type, schools.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "9YYZBytiJssO",
    "outputId": "75820579-be99-43eb-8945-73b2d41c016e"
   },
   "outputs": [],
   "source": [
    "#I select the potential independent variables as features\n",
    "features_col = ['Suburb', 'Profile', 'Amenities', 'Type','Address']\n",
    "house_data[features_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IjkPgWKCVWj"
   },
   "outputs": [],
   "source": [
    "#Clean the features by removing the stopwords, regular expressions and replace with a space\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', ' ')\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text\n",
    "\n",
    "#Applying the clean_text() to features\n",
    "#house_data['Schools'] = house_data['Schools'].apply(clean_text)\n",
    "house_data['Profile'] = house_data['Profile'].apply(clean_text)\n",
    "house_data['Amenities'] = house_data['Amenities'].apply(clean_text)\n",
    "house_data['Type'] = house_data['Type'].apply(clean_text)\n",
    "house_data['Suburb'] = house_data['Suburb'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvMixb4H4Azd"
   },
   "outputs": [],
   "source": [
    "#Further cleaning of the column 'Suburb'\n",
    "#We will remove the vic - postcode and preserve only the suburb's name\n",
    "def clean_sub(text):\n",
    "  text = text.replace('vic','')\n",
    "  return text\n",
    "\n",
    "\n",
    "house_data['Suburb'] = house_data['Suburb'].apply(clean_sub)\n",
    "house_data['Suburb'] = house_data['Suburb'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5duB5xBmeV0"
   },
   "outputs": [],
   "source": [
    "#Cleaning the house price data and converting to a numeric column\n",
    "def remove(text):\n",
    "  text = text.replace('SOLD -','')\n",
    "  text = text.replace('Price Withheld','0')\n",
    "  text = text.replace('$','')\n",
    "  text = text.replace(',','')\n",
    "  return text\n",
    "\n",
    "house_data['Price'] = house_data['Price'].apply(remove)\n",
    "house_data['Price'] = pd.to_numeric(house_data['Price'])\n",
    "house_data = house_data[house_data['Price'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "0YHR-qpNo-nU",
    "outputId": "1506291f-a264-4479-d965-4c5cf7f3dcf0"
   },
   "outputs": [],
   "source": [
    "#Plot of histogram for the house price is skewed\n",
    "house_data.hist(column='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "VcROrh7Ip2J2",
    "outputId": "1dca6eeb-cc5e-4a0f-b7a9-1bb25ed825c9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Median price of the houses\n",
    "median_price = house_data.median()\n",
    "print(median_price)\n",
    "#Replace the null values of house price data with the median figure\n",
    "house_data=house_data.replace({'Price': {0: 775000.0}})\n",
    "house_data['Price']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "bP9ZmqbQ6uWy",
    "outputId": "d20c8618-45b8-4c7c-8017-ea3be16623dd"
   },
   "outputs": [],
   "source": [
    "house_data[features_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp0OH4URDrw6"
   },
   "outputs": [],
   "source": [
    "#Remove the vacant land\n",
    "house_data = house_data[house_data['Type'] != 'vacant land']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB09si1Cst8E"
   },
   "source": [
    "Explaratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "G6jqopasMYVu",
    "outputId": "bb54a586-a9d9-4e39-d05d-d1f32e951c2f"
   },
   "outputs": [],
   "source": [
    "#Plotting house price against the type of house\n",
    "print(house_data['Type'].unique())\n",
    "df = house_data.groupby('Type')['Price'].mean()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "tKOzNE2d7DeA",
    "outputId": "d7bd15c1-ba90-4cba-9467-62d58ce9c2ec"
   },
   "outputs": [],
   "source": [
    "#PLotting house price against the suburb name\n",
    "df = house_data.groupby('Suburb')['Price'].mean()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5T4iLFotK0t"
   },
   "source": [
    "Feature Extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYVu8e_n6oeW"
   },
   "source": [
    "Extracting the number of beds/baths and parking from Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EcSd-Y_SNOD5",
    "outputId": "f75b77d5-2ef1-485d-903f-c14c82e7ac87"
   },
   "outputs": [],
   "source": [
    "house_data.Amenities[2096] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kROqUUdJC8s4"
   },
   "outputs": [],
   "source": [
    "#extracting the number of baths/beds/parkings and storing them as seperate columns \n",
    "regex = r'(?P<beds>\\d)\\sbeds?\\s(?P<bath>\\d+)\\sbaths?\\s?(?P<parking>\\d)?'\n",
    "house_data = pd.concat([house_data, house_data['Amenities'].str.extract(regex)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nK2sLlJbDMuf"
   },
   "outputs": [],
   "source": [
    "#Fill the null values in the parking column == 0\n",
    "house_data['parking'] = house_data['parking'].fillna(0)\n",
    "house_data['beds'] = house_data['beds'].fillna(0)\n",
    "house_data['bath'] = house_data['bath'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "ZE39IDaiLV0g",
    "outputId": "2086a297-d3cd-4c45-be98-359ba520b5d6"
   },
   "outputs": [],
   "source": [
    "features_col = ['Suburb', 'Type', 'beds', 'bath', 'parking']\n",
    "house_data[features_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Mfvg7Y5HoLXf",
    "outputId": "43d87e74-506b-4df2-f329-f336bba0f1e4"
   },
   "outputs": [],
   "source": [
    "house_data['beds'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "WNzG8Ilhn44c",
    "outputId": "6788ef6c-f6c1-4fe3-832d-d534cce32cf9"
   },
   "outputs": [],
   "source": [
    "df = house_data.groupby('beds')['Price'].mean()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "w6iOr7Bdn-B6",
    "outputId": "77f8ea77-e6d0-4531-88e1-de06fc367918"
   },
   "outputs": [],
   "source": [
    "df = house_data.groupby('bath')['Price'].mean()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "UgVh9QquoBmJ",
    "outputId": "21a9d4cf-4c22-496c-a678-8dd1010663e2"
   },
   "outputs": [],
   "source": [
    "df = house_data.groupby('parking')['Price'].mean()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BOUIcl26tv5"
   },
   "source": [
    "Extracting the the street names from Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY1mB8fn_daX"
   },
   "outputs": [],
   "source": [
    "df = house_data['Address'].str.split(r'[/0-9]+', expand=True).drop(columns=[0,2,3])\n",
    "df = df[1].str.split(' ', expand=True).drop(columns=[0,3,4,5,6,7])\n",
    "house_data['street'] = df[1].str.cat(df[2], sep =\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "3qQwh5096Wjm",
    "outputId": "0b896e64-8ad3-4716-a194-5c046a1a589f"
   },
   "outputs": [],
   "source": [
    "house_data.street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBroNatiXghU"
   },
   "source": [
    "Extracting the distance to the nearest school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT0yMUrqXgEx"
   },
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "  return re.search('[0-9.0-9]+', text).group()\n",
    "\n",
    "house_data['Schools'] = house_data['Schools'].apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoPg-dNy_DCY"
   },
   "outputs": [],
   "source": [
    "features_col = ['Suburb', 'Type', 'beds', 'bath', 'parking','Schools']\n",
    "house_data[features_col]\n",
    "house_data['Schools'] = pd.to_numeric(house_data['Schools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "PE5vhx_AMrC_",
    "outputId": "db814125-65f5-4abf-a419-f213bd9c6fd9"
   },
   "outputs": [],
   "source": [
    "#house' 'apartment unit flat' 'townhouse' 'new apartments plan' 'villa'\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "df_wide=house_data.pivot_table(index='Type', columns='beds', values='Price')\n",
    "\n",
    "p2=sns.heatmap(df_wide, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0gm1SmRobQU"
   },
   "source": [
    "Insights: \n",
    "1. Villa with <= 1 number of beds has the least price\n",
    "2. Apartment unit flat has the highest price for beds >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "UWBpgHzwR9hT",
    "outputId": "65fc3c2b-3fc2-42ed-c562-4478e1afd35c"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "df_wide=house_data.pivot_table(index='Type', columns='Schools', values='Price')\n",
    "\n",
    "p2=sns.heatmap(df_wide, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EksVBrtoy0A"
   },
   "source": [
    "Insights:\n",
    "1. houses with schools in close proximity (0.1 - 1.1km) are high in price. similar pattern in new apartment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaI4C2zQCDjc"
   },
   "source": [
    "Preprocessing the features before modelling\n",
    "\n",
    "Label encode the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "fqjT-ta_CDBB",
    "outputId": "b45ce27f-2d10-4f13-ca7e-a31f71d59368"
   },
   "outputs": [],
   "source": [
    "house_data[features_col].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGB6Pl7KCZzN"
   },
   "outputs": [],
   "source": [
    "#Label encode the suburbs, type and amenities\n",
    "le = LabelEncoder()\n",
    "house_data['Suburb'] = le.fit_transform(house_data['Suburb'])\n",
    "house_data['Type'] = le.fit_transform(house_data['Type'])\n",
    "house_data['beds'] = pd.to_numeric(house_data['beds'])\n",
    "house_data['bath'] = pd.to_numeric(house_data['bath'])\n",
    "house_data['parking'] = pd.to_numeric(house_data['parking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "66lP3Bd9tBs4",
    "outputId": "a7f67219-3624-4e3b-e512-10ce0bcce8e9"
   },
   "outputs": [],
   "source": [
    "house_data[features_col].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "apUfCBR7HPDP",
    "outputId": "9df30e53-58ac-4dfb-9ffd-2eea55be1003"
   },
   "outputs": [],
   "source": [
    "house_data['Schools'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "dE2r1sbFG-1b",
    "outputId": "eda0f574-ee1e-4c90-a08c-266fbf3b4e5d"
   },
   "outputs": [],
   "source": [
    "house_data.plot.scatter(x='Schools',\n",
    "                      y='Price',\n",
    "                      c='DarkBlue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOGxwTebtFdq"
   },
   "outputs": [],
   "source": [
    "#Converting the X and Y to arrays\n",
    "X = house_data[features_col].values\n",
    "Y = house_data['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0mIwATK6cZh"
   },
   "outputs": [],
   "source": [
    "#Split the test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tDDxbpi97DyR",
    "outputId": "465329ab-68f8-4c2b-954d-f3e301e9d53b"
   },
   "outputs": [],
   "source": [
    "#Converting to 2D array\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkn7br1f0-SP"
   },
   "outputs": [],
   "source": [
    "#Scaling the data to 0 - 1\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "y_train = sc.fit_transform(y_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "y_test = sc.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SK7jth1x80GZ"
   },
   "outputs": [],
   "source": [
    "#Converting the X_train, y_train, X_test, y_test into 3D arrays\n",
    "def create_dataset (X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "2pB7q09y9h8d",
    "outputId": "430b9a8e-6ad8-4e5a-caab-7034fad797f5"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = create_dataset(X_test, y_test,   \n",
    "                                TIME_STEPS)\n",
    "X_train, y_train = create_dataset(X_train,y_train, \n",
    "                                  TIME_STEPS)\n",
    "print('X_train.shape: ', X_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Bm-K8w5D-fd5",
    "outputId": "635305bb-e117-4e9f-dc64-03c3d7cf7754"
   },
   "outputs": [],
   "source": [
    "#Basic LSTM model\n",
    "def create_model():\n",
    "  regressor = Sequential()\n",
    "  # Adding the first LSTM layer and some Dropout regularisation\n",
    "  regressor.add(LSTM(units = 64, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "  regressor.add(Dropout(0.3))\n",
    "  # Adding a second LSTM layer and some Dropout regularisation\n",
    "  regressor.add(Bidirectional(LSTM(units = 64, return_sequences = True)))\n",
    "  regressor.add(Dropout(0.2))\n",
    "  # Adding a third LSTM layer and some Dropout regularisation\n",
    "  regressor.add(Bidirectional(LSTM(units = 64, return_sequences = True)))\n",
    "  regressor.add(Dropout(0.2))\n",
    "  # Adding a fourth LSTM layer and some Dropout regularisation\n",
    "  regressor.add(Bidirectional(LSTM(units = 64)))\n",
    "  regressor.add(Dropout(0.2))\n",
    "  # Adding the output layer\n",
    "  regressor.add(Dense(units = 1))\n",
    "\n",
    "  # Compiling the RNN\n",
    "  regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "  return regressor\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs = 50, batch_size = 32,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "u4DHtU_UBrrA",
    "outputId": "ac0fe910-542d-41fa-8c99-5f3adac1c3f6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Cleaning - A .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
